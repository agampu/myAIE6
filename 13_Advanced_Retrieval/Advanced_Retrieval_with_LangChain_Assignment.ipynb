{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# access your API keys without having to enter them manually\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
        "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
        "\n",
        "# Set them for the libraries to use\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "os.environ[\"COHERE_API_KEY\"] = cohere_api_key\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = langsmith_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-14 20:46:27--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: â€˜john_wick_1.csvâ€™\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-14 20:46:28 (68.6 MB/s) - â€˜john_wick_1.csvâ€™ saved [19628/19628]\n",
            "\n",
            "--2025-05-14 20:46:28--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_2.csvâ€™\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-14 20:46:28 (25.8 MB/s) - â€˜john_wick_2.csvâ€™ saved [14747/14747]\n",
            "\n",
            "--2025-05-14 20:46:28--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_3.csvâ€™\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-14 20:46:29 (18.8 MB/s) - â€˜john_wick_3.csvâ€™ saved [13888/13888]\n",
            "\n",
            "--2025-05-14 20:46:29--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: â€˜john_wick_4.csvâ€™\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-05-14 20:46:29 (26.7 MB/s) - â€˜john_wick_4.csvâ€™ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 11, 20, 46, 30, 154962)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. The film received high ratings from several reviewers, with many praising its action sequences, style, and entertainment value. For example, some reviews rated it 9 or 10 out of 10, highlighting its slickness, brutality, and coolness. Even those who gave lower ratings, such as 5 or 6, still acknowledged its interesting action and choreography. Overall, the subjective opinions suggest that viewers generally appreciated and enjoyed the film.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick film series, the story follows John Wick, a retired hitman who is drawn back into a world of violence and revenge after a series of personal attacks. In the first film, John comes out of retirement after a gangsters kill his dog and steal his car, seeking vengeance against those responsible. Throughout the series, he faces various enemies, including mobsters and professional killers, and becomes entangled in a complex underworld governed by rules and honor. The films are characterized by intense action sequences, stylish choreography, and a portrayal of a dark, criminal underworld.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people's opinions on John Wick vary. Some reviews are highly positive, praising the movies for their exciting action, stylishness, and world-building, with ratings of 8 and 10 out of 10. However, there are also negative reviews, such as one rating of 1 out of 10, criticizing the film for being boring, overly violent, and lacking plot. \\n\\nOverall, it seems that while many people enjoyed the John Wick movies, some did not, and opinions are mixed. Therefore, people did not generally have a uniformly positive or negative view of John Wick.\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There are no reviews with a rating of 10.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick film series, the main character, John Wick, is an ex-hitman who becomes involved in a series of violent and highly choreographed action scenes. The original movie, \"John Wick,\" introduces him as a man mourning the loss of his wife, who leaves him a dog as a final gift. When the dog is murdered by thugs, Wick is drawn back into the criminal underworld, seeking revenge. Throughout the series, he faces numerous assassins and enemies, showcasing intense combat and stylish choreography. The series is known for its brutal action scenes, world-building involving a secret society of assassins, and Keanu Reeves\\' portrayal of a relentless and skilled killer.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. The majority of reviews are highly positive, praising its action sequences, style, and Keanu Reeves\\' performance. For example, one review rated it 9 out of 10 and called it \"the coolest action film you\\'ll see all year,\" while another gave it a perfect score of 10 and described it as \"something special.\" However, there is at least one less favorable review for the third film in the series, giving it a 5 out of 10 and stating \"The magic is gone.\" Overall, the sentiment from the majority of reviews suggests that people generally enjoyed John Wick.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n\\n1. Review titled \"A Masterpiece & Brilliant Sequel\" â€“ URL: /review/rw4854296/?ref_=tt_urv\\n2. Review titled \"Most American action flicks released these days have poor screenplays and overuse computer-generated imagery. The John Wick franchise is one of the few exceptions, along with Mission Impossible.\" â€“ URL: /review/rw8944843/?ref_=tt_urv\\n3. Review titled \"It\\'s got its own action style!\" â€“ URL: /review/rw4860412/?ref_=tt_urv\\n\\nLet me know if you need further details!'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick series, John Wick, played by Keanu Reeves, is a retired hitman who seeks revenge after a series of tragic events. In the first film, his beloved dog is killed and his car is stolen by criminals, which motivates him to return to his violent past to track down those responsible. The storyline involves him confronting gangsters, facing a bounty on his head, and ultimately seeking justice for his loss. In the second film, after resolving issues with the Russian mafia, a new conflict arises when a mobster, Santino D'Antonio, asks Wick to carry out an assassination in Rome to help Santino climb the criminal hierarchy. Wick completes the task, but Santino then puts a contract on Wick's life, leading to a series of violent confrontations. Throughout the series, John Wick is portrayed as a lethal and efficient assassin who operates within a strict criminal code while seeking vengeance and survival.\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    #retriever=naive_retriever, llm=chat_model\n",
        "    retriever=bm25_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people's opinions on John Wick are quite mixed. Some reviewers highly praised the movies, describing them as exciting, well-choreographed, and highly entertaining, with ratings of 8, 9, or 10 out of 10. Others expressed strong criticism, describing the films as boring, repetitive, mindless action, and with poor plots, with ratings as low as 1 or 2 out of 10. \\n\\nOverall, it seems that some people really liked John Wick, especially fans of action and well-choreographed fight scenes, while others did not enjoy the films and found them dull or superficial. Therefore, peopleâ€™s opinions are divided, and it was not universally liked.\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there are reviews with a rating of 10. One such review can be found at the URL: /review/rw3109271/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick films, the main storyline centers on John Wick, a retired hitman seeking revenge after a brutal home invasion leaves his beloved dog murdered by thugs from his past. The films depict his relentless and violent quest for vengeance, showcasing intense action sequences, sophisticated choreography, and a dark, gritty world filled with assassins, crime, and morality questions. Throughout the series, John Wick confronts numerous enemies, demonstrating exceptional combat skills and a ruthless determination to protect what he loves.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/_d/fhhtv1rs2tj8322_2b9448jc0000gn/T/ipykernel_12802/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided reviews, people generally liked the John Wick series. The majority of the reviews are positive, praising the action, choreography, and entertainment value. However, there is at least one negative review criticizing John Wick 4 specifically, calling it \"horrible\" and criticizing its plot and fight scenes. Overall, most feedback appears favorable, indicating that people tend to like the John Wick series, although opinions on the latest installment vary.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the information provided, in the John Wick movies, John Wick is a retired assassin who is drawn back into violence and chaos after certain events. In the first film, he comes out of retirement after his dog is killed and his car is stolen, seeking revenge against those who wronged him. This leads to him unleashing a deadly and relentless vendetta, involving many scenes of violence and action as he fights to recover his dignity and settle old scores.\\n\\nIn the second movie, John Wick continues his violent adventures. The story begins with him retrieving a car from a chop shop, but he is soon forced back into the criminal underworld when calls in a favor from an Italian criminal, which leads him on missions across various locations, including Italy, Canada, and Manhattan, involving killing numerous assassins to help a new crime boss take over the Assassinâ€™s Guild.\\n\\nOverall, John Wick is depicted as a legendary, highly skilled hitman who displays intense violence and a relentless sense of vengeance in pursuit of his goals.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "# retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the reviews provided, people generally liked John Wick. Several reviews praise the film's action sequences, style, and Keanu Reeves' performance, with ratings frequently in the 8 to 10 range. Critics highlight its fun, slick, and exciting nature, especially for action fans. However, there are some negative opinions and lower ratings (such as 1 to 5), often criticizing the over-the-top action or lack of a substantial plot. Overall, the majority of reviews reflect a positive reception.\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL to that review is /review/rw3109271/?ref_=tt_urv.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In the John Wick series, the story revolves around John Wick, a retired hitman who is forced back into the violent underworld he once left behind. The original film depicts how Wickâ€™s life is upended when a gangsterâ€™s son kills his dog, a final gift from his late wife, which prompts Wick to seek lethal revenge against those who wronged him. Throughout the series, Wick faces various enemies, including mobsters, assassins, and criminal organizations, as he seeks justice and deals with the consequences of his past actions. The franchise features intense action, stylized fight sequences, and explores a fictional world where assassins operate under strict rules and codes of conduct.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, people generally liked John Wick. Multiple reviews praise its action sequences, style, and entertainment value, often giving high ratings like 8, 9, or 10 out of 10. Some reviews mention that the series is well received and maintains a consistent level of quality. However, there are also some lower ratings and critical comments, especially for later installments, indicating that not everyone was pleased. Overall, the majority of reviews suggest that people generally liked John Wick.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. The URL for that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In the John Wick movies, the story centers around John Wick, a retired assassin who is drawn back into a world of violence and revenge. The first film's plot begins when a group of thugs, led by the son of a Russian mobster he used to work for, break into his house, beat him up, kill his dog, and steal his car. The killing of his beloved dog, which was a gift from his deceased wife, prompts John Wick to seek vengeance. As he pursues justice, he becomes entangled in a dangerous underworld of crime, confronts various enemies, and unleashes a relentless and highly stylized wave of violence against those who wronged him. The movies explore themes of revenge, consequence, and the formidable skills of a legendary assassin.\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\" (<span style=\"color:green\">Done)\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics (<span style=\"color:green\">Done)\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why. (<span style=\"color:green\">Table at the end of the RAGAS evaluation code)\n",
        "<span style=\"color:green\"> For perfromance, I used three RAGAS metrics. For cost and latency, I used a Langmsith evaluation of all retrievers.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code.\n",
        "\n",
        "## <span style=\"color:green\"> RAGAS results \n",
        "<span style=\"color:green\">(Retriever perfromance metrics: faithfulness, context recall and context precision) I did not run all the ragas metrics, I only did the retriever specific ones. To save evaluation costs and to keep the output easy to understand and analyze.\n",
        "\n",
        "| Retriever                        | Faithfulness | Context Recall | Context Precision |\n",
        "|----------------------------------|--------------|----------------|-------------------|\n",
        "| Naive Retriever                  | 0.9647       | 1.0000         | 0.8856            |\n",
        "| BM25 Retriever                   | 0.9599       | 0.9889         | 0.7824            |\n",
        "| Multi-Query Retriever            | 0.9948       | 1.0000         | 0.7148            |\n",
        "| Parent Document Retriever        | 0.8673       | 0.9792         | 0.9838            |\n",
        "| Semantic Retriever               | 0.9924       | 1.0000         | 0.8508            |\n",
        "| Contextual Compression Retriever | 0.9799       | 1.0000         | 0.9861            |\n",
        "\n",
        "## <span style=\"color:green\"> RAGAS ANALYSIS\n",
        "\n",
        "*   <span style=\"color:green\">**Overall High Performance**: Most retrievers achieve excellent perfect context recall: so they are generally successful at retrieving all relevant information.\n",
        "\n",
        "*   <span style=\"color:green\">**Faithfulness**: The Multi-Query Retriever (0.9948) and Semantic Retriever (0.9924) lead in Faithfulness, suggesting their generated answers align very closely with the provided context.\n",
        "\n",
        "*   <span style=\"color:green\">**Precision**: The Contextual Compression Retriever (0.9861) and Parent Document Retriever (0.9838) show the highest Context Precision, meaning the context they retrieve is highly relevant to the query.\n",
        "\n",
        "*   <span style=\"color:green\">**Whats with Multi-query and parent document?**: Multi query, while top in faithfulness, it has the lowest context precision (0.7148), suggesting it might retrieve more irrelevant documents alongside the relevant ones. Parent Document has slightly lower faithfulness (0.8673) but very high precision.\n",
        "\n",
        "\n",
        "## <span style=\"color:green\"> LANGSMITH Results (Cost, Latency, Correctness)\n",
        "See https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3 for more details.\n",
        "\n",
        "\n",
        "![Naive Retriever Summary from LangSmith](LS_results.png)\n",
        "\n",
        "## <span style=\"color:green\"> LANGSMITH Analysis\n",
        "\n",
        "- <span style=\"color:green\"> All of them did fairly well with correctness. Cohere has slightly lower correctness, but it did run into a few timeout errors on some runs, so that might be it.\n",
        "- <span style=\"color:green\"> LATENCY: Ensemble did worse. Understandable. Since it tries everything. BM_25 rocked it and Cohere/MultiQuery were mid.\n",
        "- <span style=\"color:green\"> Dollar COST: Fairly low! \n",
        "- <span style=\"color:green\"> Total tokens: Parent, BM_25 and cohere are rocking it at under 20k, Ensemble is touching 60k! and the other three are mid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "#!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Golden Data Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:green\"> Imports for RAGAS and setting the llm and embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "sdg_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "sdg_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:green\"> Generate the golden test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "generator = TestsetGenerator(llm=sdg_llm, embedding_model=sdg_embeddings)\n",
        "sdg_dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I cleared the output of this cell: too long and not useful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Who is Keanu Reeves in the context of the acti...</td>\n",
              "      <td>[: 0\\nReview: The best way I can describe John...</td>\n",
              "      <td>Keanu Reeves is the actor who plays the charac...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Considering the popularity of the \"John Wick\" ...</td>\n",
              "      <td>[: 2\\nReview: With the fourth installment scor...</td>\n",
              "      <td>The review mentions that \"John Wick\" is a film...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who is Chad Stahelski and what is his role in ...</td>\n",
              "      <td>[: 3\\nReview: John wick has a very simple reve...</td>\n",
              "      <td>Chad Stahelski is the director of John Wick, a...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How does Reeves' portrayal contribute to the o...</td>\n",
              "      <td>[: 4\\nReview: Though he no longer has a taste ...</td>\n",
              "      <td>Savvy, indestructible Reeves looks right at ho...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>so like in the first review it says all these ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 13\\nReview: ... slaughtering a l...</td>\n",
              "      <td>The first review describes the film as full of...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the elaborate action sequences and the ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 23\\nReview: Rating 10/10\\nI was ...</td>\n",
              "      <td>The reviews highlight that John Wick features ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the visceral and stylized action sequen...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 9\\nReview: At first glance, John...</td>\n",
              "      <td>The visceral and stylized action sequences in ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Considering the film's lengthy runtime and its...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 9\\nReview: \"John Wick: Chapter 2...</td>\n",
              "      <td>The film 'John Wick: Chapter 2' has a runtime ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>whats up with john wick 2 and john wick chapte...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 10\\nReview: The first John Wick ...</td>\n",
              "      <td>The reviews highlight that John Wick 2, also k...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Does the review of Chapter 2 relate to the lac...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 11\\nReview: Don't believe the hy...</td>\n",
              "      <td>The review of Chapter 2 describes it as a gene...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does Ian McShane's role in the John Wick s...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 20\\nReview: After resolving his ...</td>\n",
              "      <td>In the John Wick series, Ian McShane plays Win...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How does Derek Kolstad's role as the writer in...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n: 10\\nReview: This universe, creat...</td>\n",
              "      <td>Derek Kolstad's role as the writer significant...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Who is Keanu Reeves in the context of the acti...   \n",
              "1   Considering the popularity of the \"John Wick\" ...   \n",
              "2   Who is Chad Stahelski and what is his role in ...   \n",
              "3   How does Reeves' portrayal contribute to the o...   \n",
              "4   so like in the first review it says all these ...   \n",
              "5   How do the elaborate action sequences and the ...   \n",
              "6   How do the visceral and stylized action sequen...   \n",
              "7   Considering the film's lengthy runtime and its...   \n",
              "8   whats up with john wick 2 and john wick chapte...   \n",
              "9   Does the review of Chapter 2 relate to the lac...   \n",
              "10  How does Ian McShane's role in the John Wick s...   \n",
              "11  How does Derek Kolstad's role as the writer in...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [: 0\\nReview: The best way I can describe John...   \n",
              "1   [: 2\\nReview: With the fourth installment scor...   \n",
              "2   [: 3\\nReview: John wick has a very simple reve...   \n",
              "3   [: 4\\nReview: Though he no longer has a taste ...   \n",
              "4   [<1-hop>\\n\\n: 13\\nReview: ... slaughtering a l...   \n",
              "5   [<1-hop>\\n\\n: 23\\nReview: Rating 10/10\\nI was ...   \n",
              "6   [<1-hop>\\n\\n: 9\\nReview: At first glance, John...   \n",
              "7   [<1-hop>\\n\\n: 9\\nReview: \"John Wick: Chapter 2...   \n",
              "8   [<1-hop>\\n\\n: 10\\nReview: The first John Wick ...   \n",
              "9   [<1-hop>\\n\\n: 11\\nReview: Don't believe the hy...   \n",
              "10  [<1-hop>\\n\\n: 20\\nReview: After resolving his ...   \n",
              "11  [<1-hop>\\n\\n: 10\\nReview: This universe, creat...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   Keanu Reeves is the actor who plays the charac...   \n",
              "1   The review mentions that \"John Wick\" is a film...   \n",
              "2   Chad Stahelski is the director of John Wick, a...   \n",
              "3   Savvy, indestructible Reeves looks right at ho...   \n",
              "4   The first review describes the film as full of...   \n",
              "5   The reviews highlight that John Wick features ...   \n",
              "6   The visceral and stylized action sequences in ...   \n",
              "7   The film 'John Wick: Chapter 2' has a runtime ...   \n",
              "8   The reviews highlight that John Wick 2, also k...   \n",
              "9   The review of Chapter 2 describes it as a gene...   \n",
              "10  In the John Wick series, Ian McShane plays Win...   \n",
              "11  Derek Kolstad's role as the writer significant...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sdg_dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span style=\"color:green\"> RAGAS evaluation of all the retrievers. First setup, then evaluate\n",
        "\n",
        "<span style=\"color:green\"> Ragas specific Imports, setting up a list of retrievers, a list of metrics, and setting up the llm and embeddings. This makes it easy for us to pick and choose which retrievers to evaluate with what metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAGAS Setup\n",
        "import pandas as pd\n",
        "import time\n",
        "from datasets import Dataset\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas import evaluate as ragas_evaluate # Alias to avoid conflict\n",
        "from ragas import RunConfig\n",
        "\n",
        "from ragas.metrics import (\n",
        "    Faithfulness,\n",
        "    ContextRecall,\n",
        "    ContextPrecision\n",
        ")\n",
        "\n",
        "# Commented out retrievers that often give time out errors!\n",
        "retriever_chains_to_evaluate = [\n",
        "    (\"Naive Retriever\", naive_retrieval_chain),\n",
        "    (\"BM25 Retriever\", bm25_retrieval_chain),\n",
        "    #(\"Contextual Compression Retriever\", contextual_compression_retrieval_chain),\n",
        "    (\"Multi-Query Retriever\", multi_query_retrieval_chain),\n",
        "    (\"Parent Document Retriever\", parent_document_retrieval_chain),\n",
        "    #(\"Ensemble Retriever\", ensemble_retrieval_chain),\n",
        "    (\"Semantic Retriever\", semantic_retrieval_chain)\n",
        "]\n",
        "\n",
        "metrics_to_use = [\n",
        "    Faithfulness(),\n",
        "    ContextRecall(),\n",
        "    ContextPrecision()\n",
        "]\n",
        "evaluation_run_config = RunConfig(\n",
        "    timeout=900,  # 10 minutes per job\n",
        "    max_workers=2 # Limit concurrency\n",
        ")\n",
        "\n",
        "# LLM? we defined it earlier as sdg_llm\n",
        "ragas_eval_llm_for_metrics = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "ragas_eval_embeddings_for_metrics = sdg_embeddings\n",
        "\n",
        "# For a timeout error (I git it with cohere a lot):\n",
        "#ragas_eval_llm_for_metrics = LangchainLLMWrapper(\n",
        "#    ChatOpenAI(\n",
        "#        model=\"gpt-4.1-nano\",\n",
        "#        request_timeout=120  # This is the key addition\n",
        "#    )\n",
        "#)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span style=\"color:green\"> RAGAS Evaluation: Run the evals on chosen retrievers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ragas summaries (User's Exact Workflow - No Comments) will be appended to: ragas_Retriever_summary.txt\n",
            "\n",
            "--- Evaluating: Ensemble Retriever ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "268e5dde0e0f4cacac7bf3432a49a507",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Scores for Ensemble Retriever:\n",
            "{'faithfulness': 0.9798, 'context_recall': 1.0000, 'context_precision': 0.8678}\n",
            "\n",
            "All summaries (User's Exact Workflow - No Comments) appended to: ragas_Retriever_summary.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Save the results to a file\n",
        "output_summary_filename = \"ragas_Retriever_summary.txt\"\n",
        "with open(output_summary_filename, \"w\") as f:\n",
        "    f.write(\"Ragas Summaries):\\n\\n\")\n",
        "\n",
        "print(f\"Ragas summaries to be appended to: {output_summary_filename}\\n\")\n",
        "\n",
        "# For each retriever: \n",
        "#   run its rag chain on the golden test dataset, \n",
        "#   convert the results to a pandas dataframe, and \n",
        "#   evaluate the results with RAGAS.\n",
        "for retriever_name, chain_instance in retriever_chains_to_evaluate:\n",
        "    print(f\"--- Evaluating: {retriever_name} ---\")\n",
        "    for test_sample in sdg_dataset: \n",
        "        question = test_sample.eval_sample.user_input\n",
        "        \n",
        "        response_dict = chain_instance.invoke({\"question\": question})\n",
        "        test_sample.eval_sample.response = response_dict[\"response\"].content \n",
        "        test_sample.eval_sample.retrieved_contexts = [doc.page_content for doc in response_dict[\"context\"]]\n",
        "        \n",
        "        time.sleep(6.1)\n",
        "    \n",
        "    list_of_eval_sample_dicts = [sample.eval_sample.model_dump() for sample in sdg_dataset]\n",
        "    df_for_evaluation = pd.DataFrame(list_of_eval_sample_dicts)\n",
        "    evaluation_hf_dataset = Dataset.from_pandas(df_for_evaluation)\n",
        "\n",
        "  \n",
        "    result = ragas_evaluate(\n",
        "        dataset=evaluation_hf_dataset,\n",
        "        metrics=metrics_to_use, \n",
        "        llm=ragas_eval_llm_for_metrics,\n",
        "        embeddings=ragas_eval_embeddings_for_metrics,\n",
        "        run_config=evaluation_run_config\n",
        "    )\n",
        "    summary_line = f\"Retriever: {retriever_name}\\nScores: {result}\\n-------------\\n\"\n",
        "    print(f\"\\nScores for {retriever_name}:\")\n",
        "    print(result) \n",
        "    with open(output_summary_filename, \"a\") as f:\n",
        "        f.write(summary_line)\n",
        "\n",
        "print(f\"\\nAll RAGAS eval summaries  appended to: {output_summary_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <span style=\"color:green\"> Langsmith evaluation for cost and latency.\n",
        "<span style=\"color:green\"> Same as RAGAS: we first do the setup and then run the evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:green\"> Langsmith setup: Imports, tracing, init the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "LANGCHAIN_TRACING=\"true\"\n",
        "LANGCHAIN_PROJECT= \" Assignment 13 Eval Retrievers-Test\"\n",
        "\n",
        "client = Client()\n",
        "dataset_name = \"Advanced_Retrieval_Assignment_Test\"\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Assignment 13 eval retrievers - test!\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:green\"> Convert our golden data set into Langsmith format. Langsmith was having trouble with the special formatting of the contexts. So, I tried to get around it by cleaning out all the <1-hop> markers etc and just grabbing the actual review. Then it did work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Checking LangSmith Dataset Format ===\n",
            "Context format in metadata: This universe, created without any source material, had to develop and expand itself in every new film. The same fiction can not be made for each film. We don't know if Derek Kolstad had thought that John Wick would be this big when he first created it, but when we came to the third film it seems clear how the story deepened and became beautiful.\n"
          ]
        }
      ],
      "source": [
        "def clean_context(context):\n",
        "    \"\"\"Clean the reference context by removing special formatting.\"\"\"\n",
        "    if isinstance(context, str):\n",
        "        try:\n",
        "            if context.startswith(\"[: \"):\n",
        "                parts = context.split(\"Review: \", 1)\n",
        "                return parts[1] if len(parts) > 1 else context\n",
        "            elif context.startswith(\"<1-hop>\"):\n",
        "                parts = context.split(\"Review: \", 1)\n",
        "                return parts[1] if len(parts) > 1 else context\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Error cleaning context: {e}\")\n",
        "            return context\n",
        "    return context\n",
        "\n",
        "# Convert the dataset from Ragas format to LangSmith format.\n",
        "for data_row in sdg_dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          #\"context\": data_row[1][\"reference_contexts\"]\n",
        "          \"context\": [clean_context(ctx) for ctx in data_row[1][\"reference_contexts\"]]\n",
        "\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )\n",
        "\n",
        "# Quick check of the dataset format\n",
        "print(\"=== Checking LangSmith Dataset Format ===\")\n",
        "example = next(client.list_examples(dataset_id=langsmith_dataset.id))\n",
        "print(f\"Context format in metadata: {example.metadata['context'][0]}\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:green\"> Set the lanfsmith eval llm and define the data prep util that will take the rag chain output and convert it into langsmith format.\n",
        "\n",
        "<span style=\"color:green\"> I would have liked to just do both ragas and langmsith evals together for each retriever. I would have liked to refactor the code so it does not have to run the rag chains TWICE, once for ragas, once for langsmith. I wanted to dig deeper into the possible evaluation functions RAGAS and Langsmith provide and find ones that will take the 5-column data and run the evals. But I have a lot of work backlog, so maybe later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "lc_eval_llm = ChatOpenAI(model=\"gpt-4.1\")\n",
        "\n",
        "def prep_data(run, example):\n",
        "    return {\n",
        "        \"prediction\": run.outputs['response'],  # Map 'response' key to 'prediction'\n",
        "        \"reference\": example.outputs['answer'], # Map 'answer' key to 'reference'\n",
        "        \"input\": example.inputs['question'],    # Map 'question' key to 'input' (or 'query' depending on the evaluator's prompt)\n",
        "    }\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : lc_eval_llm},prepare_data=prep_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\"color:green\"> Run the langsmith evaluators for all our retrievers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'sparkling-eye-19' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/799322e8-ed7a-405c-b3be-045ee16a42b6/compare?selectedSessions=33a431ab-d18d-4995-830e-17a0f859c6c0\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0a912192bba4d8c80534ac7af694c27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Retriever Summary:\n",
            "<ExperimentResults sparkling-eye-19>\n",
            "Error: results_object does not have 'experiment_name' or 'summary_stats' attributes. Cannot process.\n"
          ]
        }
      ],
      "source": [
        "naive_ls_results = evaluate(\n",
        "    naive_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"Base_Embedding_Model\"},\n",
        ")\n",
        "print(\"Naive Retriever Summary:\")\n",
        "print(naive_ls_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'bold-memory-92' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3/compare?selectedSessions=e7cb5a13-7f09-44ae-9288-93c4bbc64f88\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed3ed04afa1243f484d96804c9881cde",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BM25 Retriever Summary:\n",
            "<ExperimentResults bold-memory-92>\n",
            "View the evaluation results for experiment: 'dependable-clove-34' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3/compare?selectedSessions=090362fe-b209-429f-9349-4f5ebe3ac686\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5eb1948f50c4aee83c76d5d17e53c48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error running target function: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1905, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3032, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3760, in invoke\n",
            "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
            "                   ~~~~~~~~~~~~~^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3744, in _invoke_step\n",
            "    return context.run(\n",
            "           ~~~~~~~~~~~^\n",
            "        step.invoke,\n",
            "        ^^^^^^^^^^^^\n",
            "        input,\n",
            "        ^^^^^^\n",
            "        child_config,\n",
            "        ^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3034, in invoke\n",
            "    input = context.run(step.invoke, input, config)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/retrievers.py\", line 258, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "        input, run_manager=run_manager, **_kwargs\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain/retrievers/contextual_compression.py\", line 48, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "        docs, query, callbacks=run_manager.get_child()\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "        query=query,\n",
            "    ...<3 lines>...\n",
            "        max_tokens_per_doc=max_tokens_per_doc,\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/cohere/v2/client.py\", line 1113, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running evaluator <DynamicRunEvaluator evaluate> on run 0551ad17-b32d-4f6a-9dd1-daa306ba04d8: KeyError('response')\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1627, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "        run=run,\n",
            "        example=example,\n",
            "        evaluator_run_id=evaluator_run_id,\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 343, in evaluate_run\n",
            "    result = self.func(\n",
            "        run,\n",
            "        example,\n",
            "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 741, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/integrations/_langchain.py\", line 258, in evaluate\n",
            "    else self._prepare_data(run, example)\n",
            "         ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
            "  File \"/var/folders/_d/fhhtv1rs2tj8322_2b9448jc0000gn/T/ipykernel_12802/1942554861.py\", line 5, in prep_data\n",
            "    \"prediction\": run.outputs['response'],  # Map 'response' key to 'prediction'\n",
            "                  ~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'response'\n",
            "Error running target function: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1905, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "    ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3032, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3760, in invoke\n",
            "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
            "                   ~~~~~~~~~~~~~^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/opt/homebrew/Cellar/python@3.13/3.13.3/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3744, in _invoke_step\n",
            "    return context.run(\n",
            "           ~~~~~~~~~~~^\n",
            "        step.invoke,\n",
            "        ^^^^^^^^^^^^\n",
            "        input,\n",
            "        ^^^^^^\n",
            "        child_config,\n",
            "        ^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3034, in invoke\n",
            "    input = context.run(step.invoke, input, config)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/retrievers.py\", line 258, in invoke\n",
            "    result = self._get_relevant_documents(\n",
            "        input, run_manager=run_manager, **_kwargs\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain/retrievers/contextual_compression.py\", line 48, in _get_relevant_documents\n",
            "    compressed_docs = self.base_compressor.compress_documents(\n",
            "        docs, query, callbacks=run_manager.get_child()\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_cohere/rerank.py\", line 151, in compress_documents\n",
            "    for res in self.rerank(documents, query):\n",
            "               ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_cohere/rerank.py\", line 119, in rerank\n",
            "    results = self.client.rerank(\n",
            "        query=query,\n",
            "    ...<3 lines>...\n",
            "        max_tokens_per_doc=max_tokens_per_doc,\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/cohere/v2/client.py\", line 1113, in rerank\n",
            "    raise TooManyRequestsError(\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "cohere.errors.too_many_requests_error.TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 10 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}\n",
            "Error running evaluator <DynamicRunEvaluator evaluate> on run ac46b831-5972-4b18-990d-8a5b7eb93c5b: KeyError('response')\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/_runner.py\", line 1627, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "        run=run,\n",
            "        example=example,\n",
            "        evaluator_run_id=evaluator_run_id,\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 343, in evaluate_run\n",
            "    result = self.func(\n",
            "        run,\n",
            "        example,\n",
            "        langsmith_extra={\"run_id\": evaluator_run_id, \"metadata\": metadata},\n",
            "    )\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/evaluator.py\", line 741, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Users/geetachaudhry/Projects/mavenbc/code/myAIE6/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langsmith/evaluation/integrations/_langchain.py\", line 258, in evaluate\n",
            "    else self._prepare_data(run, example)\n",
            "         ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
            "  File \"/var/folders/_d/fhhtv1rs2tj8322_2b9448jc0000gn/T/ipykernel_12802/1942554861.py\", line 5, in prep_data\n",
            "    \"prediction\": run.outputs['response'],  # Map 'response' key to 'prediction'\n",
            "                  ~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'response'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contextual Compression Retriever Summary:\n",
            "<ExperimentResults dependable-clove-34>\n",
            "View the evaluation results for experiment: 'yellow-cheek-42' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3/compare?selectedSessions=735f5ddd-59c5-4d6d-81d4-bf183afdcdc2\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67c5b1cfdd824657b80dcc939ab9a3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multi-Query Retriever Summary:\n",
            "<ExperimentResults yellow-cheek-42>\n",
            "View the evaluation results for experiment: 'advanced-mass-60' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3/compare?selectedSessions=17e0fa96-235d-424e-8b3d-344e613441cc\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ef666f0bbac4427b427759051b27c10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parent Document Retriever Summary:\n",
            "<ExperimentResults advanced-mass-60>\n",
            "View the evaluation results for experiment: 'earnest-country-73' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3/compare?selectedSessions=8cf04488-cf49-48b6-aa63-85e15a99f97c\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55dd54b46e8c4b8db6ba74a0ad69508c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Retriever Summary:\n",
            "<ExperimentResults earnest-country-73>\n",
            "View the evaluation results for experiment: 'crazy-head-18' at:\n",
            "https://smith.langchain.com/o/a335557d-c0ed-4838-b6da-f98a8da2090c/datasets/bfc91aaa-6b4f-48cf-8145-9d13b8f858c3/compare?selectedSessions=d942b42c-b85e-46bb-9ffc-f61532bbaecd\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0533ba42dfa4d32bb305d0299f47431",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic Retrieval Chain Summary:\n",
            "<ExperimentResults crazy-head-18>\n"
          ]
        }
      ],
      "source": [
        "# BM25 Retriever\n",
        "bm25_ls_results = evaluate(\n",
        "    bm25_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"BM25_Retriever\"},\n",
        ")\n",
        "print(\"BM25 Retriever Summary:\")\n",
        "print(bm25_ls_results)\n",
        "\n",
        "# Contextual Compression Retriever\n",
        "compression_ls_results = evaluate(\n",
        "    contextual_compression_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"Contextual_Compression_Retriever\"},\n",
        ")\n",
        "print(\"Contextual Compression Retriever Summary:\")\n",
        "print(compression_ls_results)\n",
        "\n",
        "# Multi-Query Retriever\n",
        "multi_query_ls_results = evaluate(\n",
        "    multi_query_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"Multi_Query_Retriever\"},\n",
        ")\n",
        "print(\"Multi-Query Retriever Summary:\") \n",
        "print(multi_query_ls_results)\n",
        "\n",
        "# Parent Document Retriever\n",
        "parent_doc_ls_results = evaluate(\n",
        "    parent_document_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"Parent_Document_Retriever\"},\n",
        ")\n",
        "print(\"Parent Document Retriever Summary:\") \n",
        "print(parent_doc_ls_results)\n",
        "\n",
        "# Ensemble Retriever\n",
        "ensemble_ls_results = evaluate(\n",
        "    ensemble_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"Ensemble_Retriever\"},\n",
        ")\n",
        "print(\"Ensemble Retriever Summary:\")\n",
        "print(ensemble_ls_results)\n",
        "\n",
        "# Semantic Retrieval Chain\n",
        "semantic_ls_results = evaluate(\n",
        "    semantic_retrieval_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"Semantic_Retrieval_Chain\"},\n",
        ")\n",
        "print(\"Semantic Retrieval Chain Summary:\")\n",
        "print(semantic_ls_results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
